{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "a1BNIi6yjsoi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gpu acceleration and reduced memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ytR886_9j0AT"
   },
   "outputs": [],
   "source": [
    "path_to_file = 'Lermontov.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53gpFOjdkCDz",
    "outputId": "89377e06-d93d-4ef9-e0af-ebfd7b48f25d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 314280 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode()#.decode(encoding='utf-8')\n",
    "# Delete Unicode spescial symbol \\ufeff\n",
    "text = text.replace('\\ufeff', '')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vvlJ7RHkG4V",
    "outputId": "50e56952-3216-4d1f-afcd-4d5fab223a2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Осень\r\n",
      "\r\n",
      "\t\tЛистья в поле пожелтели,\r\n",
      "\t\tИ кружатся и летят;\r\n",
      "\t\tЛишь в бору поникши ели\r\n",
      "\t\tЗелень мрачную хранят.\r\n",
      "\t\tПод нависшею скалою\r\n",
      "\t\tУж не любит, меж цветов,\r\n",
      "\t\tПахарь отдыхать порою\r\n",
      "\t\tОт полуденных трудов.\r\n",
      "\t\tЗверь, отважный, поневоле\r\n",
      "\t\tСкрыться где-нибудь спешит.\r\n",
      "\t\tНочью месяц тускл, и поле\r\n",
      "\t\tСквозь туман лишь серебрит.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Заблуждение Купидона\r\n",
      "\r\n",
      "\t\tОднажды женщины Эрота отодрали;\r\n",
      "\t\tДосадой раздражен, упрямое дитя,\r\n",
      "\t\tНапрягши грозный лук и за обиду мстя,\r\n",
      "\t\tНе смея к женщинам, к \n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uVJRjnTWkojh"
   },
   "outputs": [],
   "source": [
    "text = text + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIZHSLBakye7",
    "outputId": "034a4468-3fdb-4a3f-811c-ccd5cccbed44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nwQjhg5rk1xO"
   },
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bGQs0nbk6FE",
    "outputId": "538b4eda-1c38-4d19-a7cd-c53cb3459f6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 92, 124, 112, ...,   1,   2,   1]),\n",
       " 'Осень\\r\\n\\r\\n\\t\\tЛистья в поле пожелтели,\\r\\n\\t\\tИ кружатся и летят;\\r\\n\\t\\tЛишь в бору поникши ели\\r\\n\\t\\tЗелень мрачную хранят.\\r\\n\\t\\tПод нависшею скалою\\r\\n\\t\\tУж не любит, меж цветов,\\r\\n\\t\\tПахарь отдыхать порою\\r\\n\\t\\tОт полуденных трудов.\\r\\n\\t\\tЗверь, отважный, поневоле\\r\\n\\t\\tСкрыться где-нибудь спешит.\\r\\n\\t\\tНочью месяц тускл, и поле\\r\\n\\t\\tСквозь туман лишь серебрит.\\r\\n\\r\\n\\r\\n\\r\\nЗаблуждение Купидона\\r\\n\\r\\n\\t\\tОднажды женщины Эрота отодрали;\\r\\n\\t\\tДосадой раздражен, упрямое дитя,\\r\\n\\t\\tНапрягши грозный лук и за обиду мстя,\\r\\n\\t\\tНе смея к женщинам, к нам ярость острой стали,\\r\\n\\t\\tНе слушая мольбы усерднейшей, стремит.\\r\\n\\t\\tВаш подлый род один!\\xa0– безумный говорит.\\r\\n\\r\\n\\t\\t*\\r\\n\\r\\n\\t\\tС тех пор-то женщина любви не знает!..\\r\\n\\t\\tИ точно как рабов считает нас она…\\r\\n\\t\\tТак в наказаниях всегда почти бывает:\\r\\n\\t\\tКоторые смирней, на тех падет вина!..\\r\\n\\r\\n\\r\\n\\r\\nЦевница\\r\\n\\r\\n\\t\\tНа склоне гор, близ вод, прохожий, зрел ли ты\\r\\n\\t\\tБеседку тайную, где грустные мечты\\r\\n\\t\\tСидят задумавшись? Над ними свод акаций:\\r\\n\\t\\tТам некогда стоял алтарь и муз и граций,\\r\\n\\t\\tИ куст прелестных роз, взлелеянных весной.\\r\\n\\t\\tТам некогда, кругом черемухи млечной\\r\\n\\t\\tСтруя свой аромат, шумя, с прибрежной ивой\\r\\n\\t\\tШутил подчас зефир и резвый и игривый.\\r\\n\\t\\tТам некогда моя последняя любовь\\r\\n\\t\\tПитала сердце мне и волновала кровь!..\\r\\n\\t\\tСокрылось всё теперь: так, поутру, туманы\\r\\n\\t\\tОт солнечных лучей редеют средь поляны.\\r\\n\\t\\tИсчезло всё теперь; но ты осталось мне,\\r\\n\\t\\tУтеха страждущих, спасенье в тишине,\\r\\n\\t\\tО милое, души святое вспоминанье!\\r\\n\\t\\tТебе ж, о мирный кров, тех дней, когда страданье\\r\\n\\t\\tНе ведало меня, я сохранил залог,\\r\\n\\t\\tКоторый умертвить не может грозный рок,\\r\\n\\t\\tМое веселие, уж взятое гробницей,\\r\\n\\t\\tИ ржавый предков меч с задумчивой цевницей!\\r\\n\\r\\n\\r\\n\\r\\nПоэт\\r\\n\\r\\n\\t\\tКогда Рафаэль вдохновенный\\r\\n\\t\\tПречистой девы лик священный\\r\\n\\t\\tЖивою кистью окончал:\\r\\n\\t\\tСвоим искусством восхищенный\\r\\n\\t\\tОн пред картиною упал!\\r\\n\\t\\tНо скоро сей порыв чудесный\\r\\n\\t\\tСлабел в груди его младой,\\r\\n\\t\\tИ утомленный и немой\\r\\n\\t\\tОн забывал огонь небесный.\\r\\n\\r\\n\\t\\tТаков поэт: чуть мысль блеснет,\\r\\n\\t\\tКак он пером своим прольет\\r\\n\\t\\tВсю ду',\n",
       " 628560,\n",
       " 628560)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int, text[:2000], len(text_as_int), len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PI1MdzOPlGLp",
    "outputId": "083b8964-5828-4bd3-fa8d-df8ad1b92ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "О\n",
      "с\n",
      "е\n",
      "н\n",
      "ь\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1bYtb-wmOSh",
    "outputId": "80b61f27-2c77-475b-d434-7578c04ff7a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Осень\\r\\n\\r\\n\\t\\tЛистья в поле пожелтели,\\r\\n\\t\\tИ кружатся и летят;\\r\\n\\t\\tЛишь в бору поникши ели\\r\\n\\t\\tЗелень мрачн'\n",
      "'ую хранят.\\r\\n\\t\\tПод нависшею скалою\\r\\n\\t\\tУж не любит, меж цветов,\\r\\n\\t\\tПахарь отдыхать порою\\r\\n\\t\\tОт полуденн'\n",
      "'ых трудов.\\r\\n\\t\\tЗверь, отважный, поневоле\\r\\n\\t\\tСкрыться где-нибудь спешит.\\r\\n\\t\\tНочью месяц тускл, и поле\\r\\n'\n",
      "'\\t\\tСквозь туман лишь серебрит.\\r\\n\\r\\n\\r\\n\\r\\nЗаблуждение Купидона\\r\\n\\r\\n\\t\\tОднажды женщины Эрота отодрали;\\r\\n\\t\\tДос'\n",
      "'адой раздражен, упрямое дитя,\\r\\n\\t\\tНапрягши грозный лук и за обиду мстя,\\r\\n\\t\\tНе смея к женщинам, к нам я'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WaTx6jYfmUtn"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9eb2PhZmeKs",
    "outputId": "e64b5076-631e-4f05-edcd-86f5aa250f82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Осень\\r\\n\\r\\n\\t\\tЛистья в поле пожелтели,\\r\\n\\t\\tИ кружатся и летят;\\r\\n\\t\\tЛишь в бору поникши ели\\r\\n\\t\\tЗелень мрач'\n",
      "Target data: 'сень\\r\\n\\r\\n\\t\\tЛистья в поле пожелтели,\\r\\n\\t\\tИ кружатся и летят;\\r\\n\\t\\tЛишь в бору поникши ели\\r\\n\\t\\tЗелень мрачн'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HPK0vwQmhX9",
    "outputId": "a5574aab-000b-4c8a-f47d-b69b5a004404"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int32, name=None), TensorSpec(shape=(64, 100), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Jy6ahPPNmnCt"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HaIhlwSjmqPc"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UVGzXqKBIJdx"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yb0KKcVHIQOO",
    "outputId": "28efd289-8894-4987-8eca-832bed75c187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 143) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCo_frzxITpe",
    "outputId": "f149eb07-b191-4ddc-8d3e-c25987ee204c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           36608     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 512)           1574912   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (64, None, 512)           2099200   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (64, None, 512)           2099200   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (64, None, 512)           2099200   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 143)           73359     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,982,479\n",
      "Trainable params: 7,982,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3Sc_ZZ-Idk8",
    "outputId": "1ed44c70-a060-4c5e-b343-2ca1bf614a93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 143), dtype=float32, numpy=\n",
       "array([[ 9.8486717e-06, -7.1308059e-06,  3.1033833e-05, ...,\n",
       "         4.1520202e-06, -1.1169072e-05,  1.7745612e-06],\n",
       "       [ 4.8011352e-05, -2.1910519e-05,  9.0504880e-05, ...,\n",
       "        -1.5568372e-05, -2.8453429e-05,  2.5424464e-05],\n",
       "       [ 1.5287301e-04, -8.5688676e-05,  1.7174584e-04, ...,\n",
       "        -5.8060130e-05, -3.8241582e-05,  7.5828299e-05],\n",
       "       ...,\n",
       "       [ 6.0719652e-03,  3.9545828e-03,  1.0188558e-03, ...,\n",
       "        -3.4155829e-03, -2.8065310e-03, -2.4990798e-03],\n",
       "       [ 5.7825218e-03,  4.2532878e-03,  1.2952526e-03, ...,\n",
       "        -3.5341354e-03, -2.6475005e-03, -2.5618761e-03],\n",
       "       [ 5.4154540e-03,  4.5373626e-03,  1.5657385e-03, ...,\n",
       "        -3.5307021e-03, -2.4734677e-03, -2.5845638e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LArorNHLInq6"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOmNC8ZyIuNu",
    "outputId": "b79c539e-bde1-4aef-ffc5-bd0629ecd61a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'ла здесь у изголовья,\\r\\n\\t\\tИ поцелуй любви горел в устах.\\r\\n\\t\\tПрости навек!\\xa0– Но вот одно желанье:\\r\\n\\t\\tП'\n",
      "\n",
      "Next Char Predictions: \n",
      " \"p.Чy&л(SЗиEгкуk\\xa0dнlБuQЩnQьГхP1h'Jг17ъ8h5:Dоaw—НЦyЯ1CДУ:#kцtИШmЮсOГ?\\rиехШDdЖдfgизе!yiШ–A'ЖЗILh0щz\\xa0go?\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MxFAY98WIy2K",
    "outputId": "172b8281-b88f-4ff8-d492-0302626c4a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 143)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.9625726\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "IzOGWWHXI-u2"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RgKMpH10JIyD"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_freq=7*10,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlGVghMMKGnV",
    "outputId": "20d0c9a5-bbb6-4c24-8ead-e50763cfae8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 106s 1s/step - loss: 3.5541\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 138s 1s/step - loss: 3.4975\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 129s 1s/step - loss: 3.4052\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 116s 1s/step - loss: 2.6012\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 122s 1s/step - loss: 2.3011\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 108s 1s/step - loss: 2.1881\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 104s 1s/step - loss: 2.0949\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 111s 1s/step - loss: 2.0153\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 101s 1s/step - loss: 1.9437\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 98s 1s/step - loss: 1.8830\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h1q8cN53KVoW",
    "outputId": "5d159fb3-b98c-4674-f4a6-6f24d233acc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_10'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vqdrgbPYQV-m"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDdvmbuqQZ6Y",
    "outputId": "096eb5af-164d-46dc-8f33-2714e9217610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 256)            36608     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (1, None, 512)            1574912   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (1, None, 512)            2099200   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (1, None, 512)            2099200   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (1, None, 512)            2099200   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 143)            73359     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,982,479\n",
      "Trainable params: 7,982,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Y1AwN3mXQczl"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, temperature=1, num_generate=500):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = num_generate\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = temperature\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVmoyLLVQ74Y",
    "outputId": "1780b492-91c6-4f07-daf7-cb77d1caafc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прекрасны горы под луной чоэоа, тоизи\r\n",
      "\r\n",
      "\t\tШилшнием шы порады\r\n",
      "\t\tТашимилный, и&#*I;ireort А' bgvncd dast гuLluerlсsn…r;\r\n",
      "1xюбы?\r\n",
      "\t\tтамем\r\n",
      "\r\n",
      "СПитаятся декожой твной,\r\n",
      "\t\tИ минях увоиситуцся талдожа;\r\n",
      "\t\tКрым, А эти-онмва, тви-есыM.Les ка-з л ебой! бебаси!\r\n",
      "\r\n",
      "\t\tУ блюгу отзвучяте,,\r\n",
      "\t\tСохяхнигуней улвюжинки нощмя;\r\n",
      "\t\tПордо пивирвих иев…? погилыf обланошы!..\r\n",
      "\t\tКагод впила, пускый рал тали, брат:\r\n",
      "\t\tК воый скудых. – 8\tTНо кгещен,\r\n",
      "\t\tПа йдаатиной, ебе краминый суявстпотет,\r\n",
      "\t\tПуколнскай; так упыкий.\r\n",
      "\t\tС тским! мои\n",
      "\r\n",
      "\t\tБетску \n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"Смотрел я на тебя \", temperature=1.5)\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIqzFtpnZme4",
    "outputId": "b33afaa9-4adc-4b2d-b2b9-4291d59e7fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прекрасны горы под луной глизанья.\r\n",
      "\t\tГоряници моя! порядый\r\n",
      "\r\n",
      "\t\tПопаревинье: беленей,\r\n",
      "\t\tНе чебе-стрен с рас куби таменвинний воимить\r\n",
      "\t\tОбогошать вично.\r\n",
      "\t\tПроздя серимайны чтодужи толкых люб.\r\n",
      "\t\tКотлув – кердо виний,\r\n",
      "\t\tИ створащовь зал спусле, кад в дотиму.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "N\r\n",
      "\r\n",
      "\t\tЯ слабото ненем погал.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "3 2\r\n",
      "\r\n",
      "\t\tИ была приматой; – всё,9»\r\n",
      "\t\tВдовасниный? – ющовли\r\n",
      "\t\tКрестоношуса ни зерденья!\r\n",
      "\t\tВ прор вободаясь очегый\r\n",
      "\t\tЯ-ворске с тикой;\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Что Рерит, был был\r\n",
      "\t\tЧтобо друг бешнумо их;\r\n",
      "\t\tТам зераныму вожить,\r\n",
      "\t\tУст\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"Смотрел я на тебя \", temperature=1)\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QySGv4r5Rxu7",
    "outputId": "40fc37b1-78f4-48ce-eead-0020396e607b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прекрасны горы под луной своей своей своей,\r\n",
      "\t\tИ старенный в нем странный володный своей своей своей странный володной,\r\n",
      "\t\tИ старить странный в нем странный своей,\r\n",
      "\t\tИ странный своей странный волода\r\n",
      "\t\tИ странит в нем странит в нем странный володной,\r\n",
      "\t\tИ старал в странный странный володной,\r\n",
      "\t\tИ странный в нем проветельный своей,\r\n",
      "\t\tИ в странит в сердце сторой своей своей странный своей,\r\n",
      "\t\tИ в нем странит в страние старал в нем странный верет,\r\n",
      "\t\tИ в нем сердце страненный володной,\r\n",
      "\t\tИ старой своей своей своей друго\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"Смотрел я на тебя \", temperature=.1)\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0x5mU0Ejbprn",
    "outputId": "4b669770-2843-4aa5-c518-bb9351bb73e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прекрасны горы под луной своей,\r\n",
      "\t\tИ старал в нем странный своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей своей свое\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"Смотрел я на тебя \", temperature=.01)\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-k54wz5RFnZ",
    "outputId": "dd48fca2-4872-40b2-f016-99eb39118359"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Смотрел я на тебя страданье\r\n",
      "\t\tОдеркним тарой вранить\r\n",
      "\t\tСвою свори всё и в сердце из его всещевься\r\n",
      "\t\tВ солду други полоркавать кагом,\r\n",
      "\t\tСторит не святой,\r\n",
      "\t\tИ счасть – вечетый забова\r\n",
      "\t\tНа своим и призимать в перед,\r\n",
      "\t\tНо разную полния гол бежды\r\n",
      "\t\tГладвенья мно провыденья\r\n",
      "\t\tСудьбовь в есть был больбовный с пустых он притоста\r\n",
      "\t\tВ давенной старенье безотним\r\n",
      "\t\tНа поред это полиной водит\r\n",
      "\t\tВ наханится не и перед\r\n",
      "\t\tВ велдену всё ти не было\r\n",
      "\t\tВ девок той душа на толо,\r\n",
      "\t\tИ слевой видал полодный,\r\n",
      "\t\tИ душа и т\n"
     ]
    }
   ],
   "source": [
    "text_ = generate_text(model, start_string=u\"Смотрел я на тебя \", temperature=.6)\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
