{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gpu acceleration and reduced memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfodePkj3jEa"
   },
   "source": [
    "#### Data load\n",
    "\n",
    "We'll use a language dataset provided by http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kRVATYOgJs1b"
   },
   "outputs": [],
   "source": [
    "# Загружаем файл\n",
    "path_to_file = \"rus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GN7B_u2FhuY",
    "outputId": "0707124f-03a5-445c-b771-77c12a086a7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.\\tМарш!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1159202 (shanghainese)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#просмотр файла\n",
    "with open(path_to_file, encoding=\"utf-8\") as f:\n",
    "    read_data = f.readline()\n",
    "read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aeHWYWLKKuM"
   },
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rd0jw-eC3jEh"
   },
   "outputs": [],
   "source": [
    "#функция препроцессинга\n",
    "def preprocess_sentence(w):\n",
    "  #переводим предложение к нижнему регистру и удалем начальные и конечные пробелы\n",
    "    w = w.lower().strip()\n",
    "\n",
    "  # отделяем пробелом слово и следующую за ним пунктуацию\n",
    "  # пример: \"he is a boy.\" => \"he is a boy .\"\n",
    "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # все, кроме букв и знаков пунктуации, заменяем пробелом\n",
    "    w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
    "  \n",
    "  #удаляем лишние пробелы в начале и конце\n",
    "    w = w.strip()\n",
    "\n",
    "  # создаем начало и конец последовательности\n",
    "  # теперь модель знает, где начинать и заканчивать предсказания\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "yV9lZXQXNbnH",
    "outputId": "58d1fce0-2947-4cae-cc26-80930d6f38ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> i can't go . <end>\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пример работы препроцессинга\n",
    "preprocess_sentence(\"I can't go.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX7WwCPhKQw1"
   },
   "source": [
    "#### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OHn4Dct23jEm"
   },
   "outputs": [],
   "source": [
    "# 1. Убираем акценты\n",
    "# 2. Очищаем предложения\n",
    "# 3. Возвращаем пары слов: [ENG, RUS]\n",
    "def create_dataset(path, num_examples):\n",
    "  #считываем строки файла\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "  #каждую строку разделяем на пробелы, берем первые 2 слова, препроцессим их и возвращаем пару\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTbSbBz55QtF",
    "outputId": "3eabaa21-afb5-4d0d-b5b6-e31b6da1ec62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> go . <end>\n",
      "<start> марш ! <end>\n"
     ]
    }
   ],
   "source": [
    "#пример работы\n",
    "en, ru = create_dataset(path_to_file, None)\n",
    "print(en[0])\n",
    "print(ru[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8j9g9AnIeZV",
    "outputId": "876d943c-cc9d-496b-a5ff-f53ba030f65b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(479223, 479223)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество данных в датасете\n",
    "len(en), len(ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0SolFHFKYSu"
   },
   "source": [
    "#### Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bIOn8RCNDJXG"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "      #токенизируем текст, отфильтвовываем пробелы\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "      #обновляем внутренний словарь на основе lang\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "      #преобразуем каждый элемент из lang в последовательность чисел\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "      #преобразуем тензор в матрицу (кол-во тензоров * max-длина), \n",
    "      #при этом короткие последовательности заполняем нулями сзади, а длинные -- обрезаем сзади\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOi42V79Ydlr"
   },
   "source": [
    "#### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eAY9k49G3jE_"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "      # создаем очищенные анг (выходные), русские (входные) пары\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "    #применяем токенизацию к каждому элементы из пары\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYWMgPrmO5zH",
    "outputId": "c6c7b44c-39e8-446c-8bb6-9abe1bb99898"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   1, 5696,   22, ...,    0,    0,    0],\n",
       "        [   1,  189,    3, ...,    0,    0,    0],\n",
       "        [   1,  282,    3, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,    6,   21, ...,    0,    0,    0],\n",
       "        [   1,   18,    7, ...,    0,    0,    0],\n",
       "        [   1,    6,   21, ...,    0,    0,    0]]),\n",
       " array([[ 1, 27,  3, ...,  0,  0,  0],\n",
       "        [ 1, 27,  3, ...,  0,  0,  0],\n",
       "        [ 1, 27,  3, ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 1,  5, 16, ...,  0,  0,  0],\n",
       "        [ 1,  5, 16, ...,  0,  0,  0],\n",
       "        [ 1,  5, 16, ...,  0,  0,  0]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 100000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnxC7q-j3jFD",
    "outputId": "0fcc760d-bd00-4940-e55c-1f94bdbb91ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычисляем максимальную длину тензоров\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "max_length_targ, max_length_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QILQkOs3jFG",
    "outputId": "a7cc5628-331f-4bad-baa8-f37b8a8eb10d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    }
   ],
   "source": [
    "# Создаем тренировочные и валидационные датасеты\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# размеры датасетов\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izb-gPZiS51c",
    "outputId": "9858a2c0-4286-4214-f1b3-8361dab6b729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   1,    6,  260, ...,    0,    0,    0],\n",
       "        [   1,    4, 9671, ...,    0,    0,    0],\n",
       "        [   1,  560,   12, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,   13,   53, ...,    0,    0,    0],\n",
       "        [   1,   12, 1657, ...,    0,    0,    0],\n",
       "        [   1, 5072, 5912, ...,    0,    0,    0]]),\n",
       " array([[   1,    5,  524, ...,    0,    0,    0],\n",
       "        [   1,    4, 4460, ...,    0,    0,    0],\n",
       "        [   1,   47,   15, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,   19,   65, ...,    0,    0,    0],\n",
       "        [   1,   22,    7, ...,    0,    0,    0],\n",
       "        [   1,   24, 2252, ...,    0,    0,    0]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train, target_tensor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lJPmLZGMeD5q"
   },
   "outputs": [],
   "source": [
    "#функция получения из токена текста (выводим токен и его индекс)\n",
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXukARTDd7MT",
    "outputId": "80add740-d0ff-489c-9f89-67652b0a13d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "6 ----> том\n",
      "260 ----> говорит\n",
      "9 ----> ,\n",
      "17 ----> что\n",
      "19 ----> он\n",
      "15 ----> в\n",
      "183 ----> порядке\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "5 ----> tom\n",
      "524 ----> says\n",
      "124 ----> he's\n",
      "439 ----> fine\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TqHsArVZ3jFS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "#количество эпох\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 300\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "#из каждого элемента (input_tensor_train, target_tensor_train) создает тензор\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "#разбиваем датасет на батчи (списки по 64), удаляя последний неполный батч\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qc6-NK1GtWQt",
    "outputId": "1f514854-cd55-4014-fc4c-ee83587dd04b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 15) (64, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(15,), dtype=int32, numpy=\n",
       " array([   1, 6387,  261, 1913,   49,    3,    2,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0])>,\n",
       " <tf.Tensor: shape=(11,), dtype=int32, numpy=array([  1, 406, 171,  61,  15,   3,   2,   0,   0,   0,   0])>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "print(example_input_batch.shape, example_target_batch.shape)\n",
    "example_input_batch[0], example_target_batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "#### Machine translation model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXu4a6IRU3SH"
   },
   "source": [
    "**Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=False,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "    #создаем тензор из нулей размера (батч, кол-во ячеек)\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60gSVh05Jl6l",
    "outputId": "adc97513-f014-4fe4-bc99-37761f0165fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# инициализитеруем начальное скрытое состояние (из нулей)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "# применяем энкодер к входному батчу и скрытому состоянию\n",
    "sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "# print ('Форма выхода энкодера: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlYuNwZSYvAA",
    "outputId": "97ff4185-2919-467d-f6ee-e18871528e89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       "array([[-1.20029990e-02,  1.66133360e-03, -6.31120129e-05, ...,\n",
       "        -1.43919522e-02,  1.44618331e-02, -8.83039646e-03],\n",
       "       [-1.19978283e-02,  1.78099168e-03, -1.80959658e-04, ...,\n",
       "        -1.45703126e-02,  1.48877455e-02, -8.86684842e-03],\n",
       "       [-1.19848596e-02,  1.80697208e-03, -1.44916470e-04, ...,\n",
       "        -1.47417625e-02,  1.48633337e-02, -8.91372934e-03],\n",
       "       ...,\n",
       "       [-1.19560324e-02,  1.79350632e-03,  2.82718029e-05, ...,\n",
       "        -1.41730700e-02,  1.44670717e-02, -8.68918840e-03],\n",
       "       [-1.21374270e-02,  1.78678287e-03, -8.99007937e-05, ...,\n",
       "        -1.45864338e-02,  1.47088431e-02, -8.83869920e-03],\n",
       "       [-1.19473143e-02,  1.84538972e-03, -8.22641668e-05, ...,\n",
       "        -1.46181956e-02,  1.46132344e-02, -8.85110255e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4Xlb0QdU8pu"
   },
   "source": [
    "**Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yJ_B3mhW3jFk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        # x shape после прохождения через эмбеддинг == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # отправляем в GRU входные данные и скрытое состояние (от энкодера)\n",
    "        #выход GRU (batch_size, timesteps, units)\n",
    "        #размер возвращаемого внутреннего состояния (batch_size, units)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # x shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5UY8wko3jFp",
    "outputId": "7053ca1e-71f5-4bef-f4e9-3062d7838cf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 7386]), TensorShape([64, 1024]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "#применяем декодер к случайному батчу из равномерного распределения (батч,1) и выходу энкодера\n",
    "decoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden)\n",
    "decoder_sample_x.shape, decoder_sample_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKcypC0AGeLR",
    "outputId": "0ecb652a-937d-45e5-e23b-460b294f377d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 7386), dtype=float32, numpy=\n",
       "array([[ 0.00777631,  0.0015943 , -0.00565019, ...,  0.00313168,\n",
       "         0.00354554,  0.0038535 ],\n",
       "       [ 0.00781316,  0.00156634, -0.00558414, ...,  0.00325799,\n",
       "         0.00362245,  0.0038099 ],\n",
       "       [ 0.00784024,  0.00148141, -0.00558086, ...,  0.00323906,\n",
       "         0.003685  ,  0.00381215],\n",
       "       ...,\n",
       "       [ 0.00777819,  0.00156104, -0.00565952, ...,  0.00320803,\n",
       "         0.00351055,  0.003876  ],\n",
       "       [ 0.00780508,  0.00153168, -0.00561464, ...,  0.0031972 ,\n",
       "         0.00362976,  0.00383433],\n",
       "       [ 0.00781009,  0.00153064, -0.00559916, ...,  0.00319188,\n",
       "         0.00363257,  0.00384646]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sample_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "#### Model compilling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "#оптимизатор\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "#функция потерь\n",
    "def loss_function(real, pred):\n",
    "      #делаем инверсию значений сравнения каждого из real с нулем (возвращается true или false)\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "      #применяем функцию ошибок к реальным данным и предсказанным\n",
    "    loss_ = loss_object(real, pred)\n",
    "      #приводим тензор mask к новому типу loss_.dtype\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "      #умножаем loss_ на mask\n",
    "    loss_ *= mask\n",
    "      # возвращаем среднее значениe всех элементов\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOiIW8xam8db"
   },
   "source": [
    "**Сheckpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Zj8bXQTgNwrF"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_nmt_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpzKPhSZckWL"
   },
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "sC9ArXSsVfqn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "  # перечисляем операции для автоматического дифференцирования\n",
    "    with tf.GradientTape() as tape:\n",
    "        #получаем выход encoder\n",
    "        enc_hidden = encoder(inp, enc_hidden)\n",
    "        #помещаем его в скрытое состояние decoder\n",
    "        dec_hidden = enc_hidden\n",
    "        #формируем вход декодера:\n",
    "                 # берем список длины батч из индексов тега <start> (1)\n",
    "                 # приписываем списку размерность 1 сзади (батч, 1)\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - выводим target в качестве следующего входа\n",
    "        for t in range(1, targ.shape[1]):\n",
    "          # помещаем enc_output в decoder\n",
    "            predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "          # считаем функцию потерь \n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "          # используем teacher forcing (приписываем списку размерность 1 сзади)\n",
    "          #посылаем dec_input на вход декордера \n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    #переменные\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    #вычисляем градиенты loss по variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    #оптимизатор применяет подсчитанные градиенты\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddefjBMa3jF0",
    "outputId": "a9bba3e5-4d62-4b14-a173-6ac857359375",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.3908\n",
      "Epoch 1 Batch 100 Loss 0.3011\n",
      "Epoch 1 Batch 200 Loss 0.3685\n",
      "Epoch 1 Batch 300 Loss 0.3820\n",
      "Epoch 1 Batch 400 Loss 0.4277\n",
      "Epoch 1 Batch 500 Loss 0.3743\n",
      "Epoch 1 Batch 600 Loss 0.4398\n",
      "Epoch 1 Batch 700 Loss 0.3606\n",
      "Epoch 1 Batch 800 Loss 0.4213\n",
      "Epoch 1 Batch 900 Loss 0.3317\n",
      "Epoch 1 Batch 1000 Loss 0.3709\n",
      "Epoch 1 Batch 1100 Loss 0.3263\n",
      "Epoch 1 Batch 1200 Loss 0.4087\n",
      "Epoch 1 Loss 0.3919\n",
      "Time taken for 1 epoch 327.7747747898102 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.2616\n",
      "Epoch 2 Batch 100 Loss 0.2309\n",
      "Epoch 2 Batch 200 Loss 0.2099\n",
      "Epoch 2 Batch 300 Loss 0.2204\n",
      "Epoch 2 Batch 400 Loss 0.2017\n",
      "Epoch 2 Batch 500 Loss 0.2447\n",
      "Epoch 2 Batch 600 Loss 0.2209\n",
      "Epoch 2 Batch 700 Loss 0.2598\n",
      "Epoch 2 Batch 800 Loss 0.2371\n",
      "Epoch 2 Batch 900 Loss 0.2182\n",
      "Epoch 2 Batch 1000 Loss 0.3098\n",
      "Epoch 2 Batch 1100 Loss 0.2084\n",
      "Epoch 2 Batch 1200 Loss 0.2756\n",
      "Epoch 2 Loss 0.2294\n",
      "Time taken for 1 epoch 344.6755602359772 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.1246\n",
      "Epoch 3 Batch 100 Loss 0.1633\n",
      "Epoch 3 Batch 200 Loss 0.1257\n",
      "Epoch 3 Batch 300 Loss 0.1409\n",
      "Epoch 3 Batch 400 Loss 0.1642\n",
      "Epoch 3 Batch 500 Loss 0.1351\n",
      "Epoch 3 Batch 600 Loss 0.1257\n",
      "Epoch 3 Batch 700 Loss 0.1691\n",
      "Epoch 3 Batch 800 Loss 0.2170\n",
      "Epoch 3 Batch 900 Loss 0.1505\n",
      "Epoch 3 Batch 1000 Loss 0.1930\n",
      "Epoch 3 Batch 1100 Loss 0.1518\n",
      "Epoch 3 Batch 1200 Loss 0.1811\n",
      "Epoch 3 Loss 0.1536\n",
      "Time taken for 1 epoch 341.60635590553284 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0927\n",
      "Epoch 4 Batch 100 Loss 0.1107\n",
      "Epoch 4 Batch 200 Loss 0.0917\n",
      "Epoch 4 Batch 300 Loss 0.1233\n",
      "Epoch 4 Batch 400 Loss 0.1071\n",
      "Epoch 4 Batch 500 Loss 0.1438\n",
      "Epoch 4 Batch 600 Loss 0.0814\n",
      "Epoch 4 Batch 700 Loss 0.1204\n",
      "Epoch 4 Batch 800 Loss 0.1200\n",
      "Epoch 4 Batch 900 Loss 0.0854\n",
      "Epoch 4 Batch 1000 Loss 0.1532\n",
      "Epoch 4 Batch 1100 Loss 0.1436\n",
      "Epoch 4 Batch 1200 Loss 0.1085\n",
      "Epoch 4 Loss 0.1174\n",
      "Time taken for 1 epoch 355.32897543907166 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0544\n",
      "Epoch 5 Batch 100 Loss 0.0637\n",
      "Epoch 5 Batch 200 Loss 0.1101\n",
      "Epoch 5 Batch 300 Loss 0.1010\n",
      "Epoch 5 Batch 400 Loss 0.1212\n",
      "Epoch 5 Batch 500 Loss 0.0640\n",
      "Epoch 5 Batch 600 Loss 0.0734\n",
      "Epoch 5 Batch 700 Loss 0.0734\n",
      "Epoch 5 Batch 800 Loss 0.0711\n",
      "Epoch 5 Batch 900 Loss 0.1200\n",
      "Epoch 5 Batch 1000 Loss 0.1222\n",
      "Epoch 5 Batch 1100 Loss 0.1530\n",
      "Epoch 5 Batch 1200 Loss 0.1440\n",
      "Epoch 5 Loss 0.0989\n",
      "Time taken for 1 epoch 335.369747877121 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "  #инициализируем входное скрытое состояние (из нулей) размера (батч, кол-во рекуррентных ячеек)\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        #делаем шаг обучения. находим оштбку за этоху\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        #считаем ошибку\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                       batch,\n",
    "                                                       batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU3Ce8M6I3rz"
   },
   "source": [
    "#### Translate\n",
    "* Функция оценки аналогична циклу обучения, за исключением того, что здесь мы не используем *teacher forcing*. Входным сигналом для декодера на каждом временном шаге являются его предыдущие предсказания вместе со скрытым состоянием и выходным сигналом энкодера.\n",
    "* Предсказания модели прекращаются, когда модель предскажет *end token*.\n",
    "* Сохраняем *веса внимания для каждого временного шага*.\n",
    "\n",
    "Примечание: Выходной сигнал энкодера вычисляется только один раз для одного входа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "EbQpyYs13jF_"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  #препоцессим предложение\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "      #разбиваем предложение по пробелам и составляем список индексов каждого слова\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "      #добиваем inputs нулями справа до максимальной длины входного текста\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                             maxlen=max_length_inp,\n",
    "                                                             padding='post')\n",
    "      #преобразуем inputs в тензор\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "      # инициализируем входной хидден из нулей размера (1, units)\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "      #подаем inputs и hidden в encoder\n",
    "    enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "      #инициализируем входной хидден декодера -- выходной хидден энкодера\n",
    "    dec_hidden = enc_hidden\n",
    "      #вход декодера -- список [индекс start] размера(1,1)\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "            #получаем выход декодера\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "   #заканчиваем на токене end\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence\n",
    "\n",
    "    # предсказанный predicted ID подаем обратно в декодер (размер (1,1))\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "sl9zUHzg3jGI"
   },
   "outputs": [],
   "source": [
    "#функция перевода\n",
    "def translate(sentence):\n",
    "    result, sentence = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJpT9D5_OgP6",
    "outputId": "15ae2f03-f443-4d24-d452-f4b7923cfeca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x25467b5e6d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем последний checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FG7aFl1X4kEx",
    "outputId": "c8614c58-a284-452b-9856-882ec76b7e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> моросит <end>\n",
      "Predicted translation: it's completely dark . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Моросит')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bhFfwcIMX5i",
    "outputId": "4c215149-690a-4257-dc1a-68d7dcc6fe70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> идет дождь <end>\n",
      "Predicted translation: it's raining . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Идет дождь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQvAPi_k4kEy",
    "outputId": "98c935e6-bf2e-42ae-bc39-60249816c50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> завтра мне идти на работу <end>\n",
      "Predicted translation: i'll go back to my job . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Завтра мне идти на работу')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSx2iM36EZQZ",
    "outputId": "aebda207-d96f-47e1-85df-90210be238f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> завтра не наступит никогда <end>\n",
      "Predicted translation: tomorrow won't be fixed . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Завтра не наступит никогда')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TW3XfASHhjTj",
    "outputId": "a1e68fee-f6d3-4a5f-d729-7858e6825eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> во дворе трава , на траве дрова <end>\n",
      "Predicted translation: all of us is in french . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Во дворе трава, на траве дрова')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-uitVQ64kEz",
    "outputId": "3fe82735-f3fa-49d0-c875-06a1fbc90a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> что делать если ничего не хочется ? <end>\n",
      "Predicted translation: what do i say no ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Что делать если ничего не хочется?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> перевод предложения зависит от словарь на котором построена модель <end>\n",
      "Predicted translation: the feud is over . <end> \n"
     ]
    }
   ],
   "source": [
    "translate('Перевод предложения зависит от словарь на котором построена модель')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Znjc0G054kE0"
   },
   "source": [
    "#### Вывод: \n",
    "Из-за малого словаря имеется ряд неточностей в переводе, также наблюдается ряд неточностей при переводе длинных предложений. Это обусловлено отсутствием \"внимания\"."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW_10_colab.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
